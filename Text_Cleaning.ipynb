{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5debf3",
   "metadata": {},
   "source": [
    "### Text Cleaning Function\n",
    "\n",
    "This notebook contains a helpful function to strip duplicated sentences and normalise unstructured text data as a preparation step for loading into a LLM.\n",
    "\n",
    "I will be populating a dataframe of customer product ratings at random to use for testing the cleaning functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235e5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "886185f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date     id                                         transcript\n",
      "0     2025-08-24  91846  Setup was quick and easy. Setup was quick and ...\n",
      "1     2025-08-23  29186  This was by far the worst customer experience ...\n",
      "2     2025-08-22  37302  The product exceeded my expectations! I found ...\n",
      "3     2025-08-21  94733  I found the quality to be outstanding. I found...\n",
      "4     2025-08-20  20467  I found the quality to be outstanding. I have ...\n",
      "...          ...    ...                                                ...\n",
      "1995  2020-03-08  35717  Value for money is excellent. I'm very satisfi...\n",
      "1996  2020-03-07  87191  I found the quality to be outstanding. I found...\n",
      "1997  2020-03-06  16364  It works exactly as described. It works exactl...\n",
      "1998  2020-03-05  64005  It works exactly as described. I found the qua...\n",
      "1999  2020-03-04  60862  Setup was quick and easy. It works exactly as ...\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Helper function to generate a random 5-digit ID\n",
    "def generate_id():\n",
    "    return str(random.randint(10000, 99999))\n",
    "\n",
    "# Sample sentences to use in transcripts\n",
    "sentences = [\n",
    "    \"The product exceeded my expectations!\",\n",
    "    \"Delivery was prompt and hassle-free, how do I order more?\",\n",
    "    \"I found the quality to be outstanding.\",\n",
    "    \"Customer service was very helpful.\",\n",
    "    \"I would definitely recommend this to others.\",\n",
    "    \"The packaging was neat and secure.\",\n",
    "    \"It works exactly as described.\",\n",
    "    \"Value for money is excellent.\",\n",
    "    \"Setup was quick and easy.\",\n",
    "    \"I'm very satisfied with my purchase.\",\n",
    "    \"This was by far the worst customer experience I have had!\",\n",
    "    \"I have tried to return this product on numerous occasions but was declined!\",\n",
    "    \"Why would anyone suggest this product for use?\"\n",
    "]\n",
    "\n",
    "# Function to create a transcript with repeated sentences\n",
    "def create_transcript():\n",
    "    selected = random.sample(sentences, k=random.randint(3, 5))\n",
    "    repeated = [random.choice(selected) for _ in range(random.randint(1, 3))]\n",
    "    all_sentences = selected + repeated\n",
    "    random.shuffle(all_sentences)\n",
    "    transcript = \" \".join(all_sentences)\n",
    "    return \" \".join(transcript.split()[:100])  # Ensure max 100 words\n",
    "\n",
    "# Generate the DataFrame\n",
    "num_rows = 2000\n",
    "start_date = datetime.today()\n",
    "\n",
    "data = {\n",
    "    \"date\": [(start_date - timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(num_rows)],\n",
    "    \"id\": [generate_id() for _ in range(num_rows)],\n",
    "    \"transcript\": [create_transcript() for _ in range(num_rows)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde91178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended sample size: 323\n",
      "Recommended sample size: 384.1599999999999\n"
     ]
    }
   ],
   "source": [
    "# Taking a meaningful sample:\n",
    "\n",
    "# Parameters\n",
    "Z = 1.96  # 95% confidence\n",
    "p = 0.5   # conservative estimate\n",
    "E = 0.05  # ±5% margin of error\n",
    "N = len(df)  # total output length\n",
    "\n",
    "# Standard Sample Size Equation - assumes a VERY LARGE or finite population:\n",
    "n = (Z**2 * p * (1 - p)) / (E**2)\n",
    "\n",
    "# Adjusted for finite population by reducing n and maintaining significance:\n",
    "n_adj = math.ceil(n / (1 + ((n - 1) / N)))\n",
    "\n",
    "print(f\"Recommended sample size: {n_adj}\")\n",
    "print(f\"Recommended sample size: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "732e0cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date     id                                         transcript\n",
      "1860  2020-07-21  50197  It works exactly as described. Setup was quick...\n",
      "353   2024-09-05  71216  This was by far the worst customer experience ...\n",
      "1333  2021-12-30  54326  Why would anyone suggest this product for use?...\n",
      "905   2023-03-03  53918  Why would anyone suggest this product for use?...\n",
      "1289  2022-02-12  77853  I found the quality to be outstanding. The pro...\n",
      "323\n"
     ]
    }
   ],
   "source": [
    "# Take a simple random sample:\n",
    "random_sample = df.sample(n=n_adj, random_state=42)\n",
    "\n",
    "# Save or inspect the sample:\n",
    "print(random_sample.head())\n",
    "\n",
    "# confirm sample size:\n",
    "print(len(random_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc00b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# check for dupes:\n",
    "random_sample['UID'] =  df['date'].astype(str) + '_' + df['id'].astype(str)\n",
    "\n",
    "# print(random_sample.head())\n",
    "\n",
    "# Count how many times each UID appears\n",
    "uid_counts = random_sample['UID'].value_counts()\n",
    "\n",
    "# Filter to show only duplicates (i.e., count > 1)\n",
    "duplicates = uid_counts[uid_counts > 1]\n",
    "\n",
    "# Display the result\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26124b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryce\\AppData\\Local\\Temp\\ipykernel_18788\\1743261405.py:6: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  lambda x: '.\\n'.join([s for s in pd.unique([s.strip().lower() for s in re.split(r'[.!?]\\s+', x)]) if s])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>UID</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>50197</td>\n",
       "      <td>It works exactly as described. Setup was quick...</td>\n",
       "      <td>2020-07-21_50197</td>\n",
       "      <td>it works exactly as described.\\nsetup was quic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>71216</td>\n",
       "      <td>This was by far the worst customer experience ...</td>\n",
       "      <td>2024-09-05_71216</td>\n",
       "      <td>this was by far the worst customer experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>54326</td>\n",
       "      <td>Why would anyone suggest this product for use?...</td>\n",
       "      <td>2021-12-30_54326</td>\n",
       "      <td>why would anyone suggest this product for use....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>53918</td>\n",
       "      <td>Why would anyone suggest this product for use?...</td>\n",
       "      <td>2023-03-03_53918</td>\n",
       "      <td>why would anyone suggest this product for use....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>77853</td>\n",
       "      <td>I found the quality to be outstanding. The pro...</td>\n",
       "      <td>2022-02-12_77853</td>\n",
       "      <td>i found the quality to be outstanding.\\nthe pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     id                                         transcript  \\\n",
       "1860  2020-07-21  50197  It works exactly as described. Setup was quick...   \n",
       "353   2024-09-05  71216  This was by far the worst customer experience ...   \n",
       "1333  2021-12-30  54326  Why would anyone suggest this product for use?...   \n",
       "905   2023-03-03  53918  Why would anyone suggest this product for use?...   \n",
       "1289  2022-02-12  77853  I found the quality to be outstanding. The pro...   \n",
       "\n",
       "                   UID                                       cleaned_text  \n",
       "1860  2020-07-21_50197  it works exactly as described.\\nsetup was quic...  \n",
       "353   2024-09-05_71216  this was by far the worst customer experience ...  \n",
       "1333  2021-12-30_54326  why would anyone suggest this product for use....  \n",
       "905   2023-03-03_53918  why would anyone suggest this product for use....  \n",
       "1289  2022-02-12_77853  i found the quality to be outstanding.\\nthe pr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lambda:\n",
    "\n",
    "# create new column for the cleaned original data (cleaned_summary):\n",
    "random_sample['cleaned_text'] = random_sample['transcript'].apply(\n",
    "\n",
    "    lambda x: '.\\n'.join([s for s in pd.unique([s.strip().lower() for s in re.split(r'[.!?]\\s+', x)]) if s])\n",
    "\n",
    ")\n",
    "\n",
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9bf855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>UID</th>\n",
       "      <th>duplicate_sentences</th>\n",
       "      <th>text_without_duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>85914</td>\n",
       "      <td>Value for money is excellent. Delivery was pro...</td>\n",
       "      <td>2020-07-21_85914</td>\n",
       "      <td>Value for money is excellent.\\nDelivery was pr...</td>\n",
       "      <td>Value for money is excellent.\\nDelivery was pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>33304</td>\n",
       "      <td>Value for money is excellent. The product exce...</td>\n",
       "      <td>2024-09-05_33304</td>\n",
       "      <td>The product exceeded my expectations!\\nThe pro...</td>\n",
       "      <td>Value for money is excellent.\\nThe product exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>88122</td>\n",
       "      <td>I found the quality to be outstanding. Deliver...</td>\n",
       "      <td>2021-12-30_88122</td>\n",
       "      <td>I found the quality to be outstanding.\\nDelive...</td>\n",
       "      <td>I found the quality to be outstanding.\\nDelive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>55857</td>\n",
       "      <td>I have tried to return this product on numerou...</td>\n",
       "      <td>2023-03-03_55857</td>\n",
       "      <td>Why would anyone suggest this product for use?</td>\n",
       "      <td>I have tried to return this product on numerou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>31244</td>\n",
       "      <td>Value for money is excellent. Value for money ...</td>\n",
       "      <td>2022-02-12_31244</td>\n",
       "      <td>Value for money is excellent.\\nWhy would anyon...</td>\n",
       "      <td>Value for money is excellent.\\nWhy would anyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>78893</td>\n",
       "      <td>The packaging was neat and secure. Customer se...</td>\n",
       "      <td>2020-09-09_78893</td>\n",
       "      <td>The packaging was neat and secure.</td>\n",
       "      <td>The packaging was neat and secure.\\nCustomer s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>56872</td>\n",
       "      <td>Value for money is excellent. Value for money ...</td>\n",
       "      <td>2021-05-04_56872</td>\n",
       "      <td>Value for money is excellent.\\nSetup was quick...</td>\n",
       "      <td>Value for money is excellent.\\nI have tried to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>35104</td>\n",
       "      <td>The product exceeded my expectations! The prod...</td>\n",
       "      <td>2025-07-11_35104</td>\n",
       "      <td>The product exceeded my expectations!\\nI would...</td>\n",
       "      <td>The product exceeded my expectations!\\nWhy wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>23928</td>\n",
       "      <td>Why would anyone suggest this product for use?...</td>\n",
       "      <td>2021-01-11_23928</td>\n",
       "      <td>Why would anyone suggest this product for use?...</td>\n",
       "      <td>Why would anyone suggest this product for use?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>28672</td>\n",
       "      <td>Delivery was prompt and hassle-free, how do I ...</td>\n",
       "      <td>2025-03-09_28672</td>\n",
       "      <td>Delivery was prompt and hassle-free, how do I ...</td>\n",
       "      <td>Delivery was prompt and hassle-free, how do I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     id                                         transcript  \\\n",
       "1860  2020-07-21  85914  Value for money is excellent. Delivery was pro...   \n",
       "353   2024-09-05  33304  Value for money is excellent. The product exce...   \n",
       "1333  2021-12-30  88122  I found the quality to be outstanding. Deliver...   \n",
       "905   2023-03-03  55857  I have tried to return this product on numerou...   \n",
       "1289  2022-02-12  31244  Value for money is excellent. Value for money ...   \n",
       "...          ...    ...                                                ...   \n",
       "1810  2020-09-09  78893  The packaging was neat and secure. Customer se...   \n",
       "1573  2021-05-04  56872  Value for money is excellent. Value for money ...   \n",
       "44    2025-07-11  35104  The product exceeded my expectations! The prod...   \n",
       "1686  2021-01-11  23928  Why would anyone suggest this product for use?...   \n",
       "168   2025-03-09  28672  Delivery was prompt and hassle-free, how do I ...   \n",
       "\n",
       "                   UID                                duplicate_sentences  \\\n",
       "1860  2020-07-21_85914  Value for money is excellent.\\nDelivery was pr...   \n",
       "353   2024-09-05_33304  The product exceeded my expectations!\\nThe pro...   \n",
       "1333  2021-12-30_88122  I found the quality to be outstanding.\\nDelive...   \n",
       "905   2023-03-03_55857     Why would anyone suggest this product for use?   \n",
       "1289  2022-02-12_31244  Value for money is excellent.\\nWhy would anyon...   \n",
       "...                ...                                                ...   \n",
       "1810  2020-09-09_78893                 The packaging was neat and secure.   \n",
       "1573  2021-05-04_56872  Value for money is excellent.\\nSetup was quick...   \n",
       "44    2025-07-11_35104  The product exceeded my expectations!\\nI would...   \n",
       "1686  2021-01-11_23928  Why would anyone suggest this product for use?...   \n",
       "168   2025-03-09_28672  Delivery was prompt and hassle-free, how do I ...   \n",
       "\n",
       "                                text_without_duplicates  \n",
       "1860  Value for money is excellent.\\nDelivery was pr...  \n",
       "353   Value for money is excellent.\\nThe product exc...  \n",
       "1333  I found the quality to be outstanding.\\nDelive...  \n",
       "905   I have tried to return this product on numerou...  \n",
       "1289  Value for money is excellent.\\nWhy would anyon...  \n",
       "...                                                 ...  \n",
       "1810  The packaging was neat and secure.\\nCustomer s...  \n",
       "1573  Value for money is excellent.\\nI have tried to...  \n",
       "44    The product exceeded my expectations!\\nWhy wou...  \n",
       "1686  Why would anyone suggest this product for use?...  \n",
       "168   Delivery was prompt and hassle-free, how do I ...  \n",
       "\n",
       "[323 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Long form function which will provide the output of what was extracted\n",
    "\n",
    "def extract_sentences_and_update_df(df, column_name):\n",
    "\n",
    "    # Regex to split sentences based on punctuation followed by whitespace\n",
    "\n",
    "    sentence_endings = re.compile(r\"\"\"\n",
    "\n",
    "        (?<=        # look behind: match if preceded by.\n",
    "\n",
    "        [.!?]       # Sentence ending punctuation.\n",
    "\n",
    "        )\\s+        # Followed by one or more whitespace characters.\n",
    "\n",
    "        \"\"\", re.X)\n",
    "\n",
    " \n",
    "\n",
    "    all_original_sentences = []\n",
    "\n",
    "    all_cleaned_sentences = []\n",
    "\n",
    " \n",
    "\n",
    "    # Collect all sentences across the column\n",
    "\n",
    "    for paragraph in df[column_name].dropna():\n",
    "\n",
    "        sentences = sentence_endings.split(paragraph.strip())\n",
    "\n",
    "        for sentence in sentences:\n",
    "\n",
    "            if sentence.strip():\n",
    "\n",
    "                cleaned = re.sub(r'\\W+', '', sentence.lower())\n",
    "\n",
    "                all_original_sentences.append(sentence.strip())\n",
    "\n",
    "                all_cleaned_sentences.append(cleaned)\n",
    "\n",
    " \n",
    "\n",
    "    # Identify duplicates\n",
    "\n",
    "    sentence_counts = Counter(all_cleaned_sentences)\n",
    "\n",
    "    duplicate_cleaned = {s for s, count in sentence_counts.items() if count > 1}\n",
    "\n",
    " \n",
    "\n",
    "    # Map cleaned to original sentence\n",
    "\n",
    "    cleaned_to_original = {}\n",
    "\n",
    "    for orig, clean in zip(all_original_sentences, all_cleaned_sentences):\n",
    "\n",
    "        if clean in duplicate_cleaned and clean not in cleaned_to_original:\n",
    "\n",
    "            cleaned_to_original[clean] = orig\n",
    "\n",
    " \n",
    "\n",
    "    # Create new columns for each row\n",
    "\n",
    "    duplicate_sentences_column = []\n",
    "\n",
    "    texts_without_duplicates_column = []\n",
    "\n",
    " \n",
    "\n",
    "    for paragraph in df[column_name]:\n",
    "\n",
    "        if pd.isna(paragraph):\n",
    "\n",
    "            duplicate_sentences_column.append(\"\")\n",
    "\n",
    "            texts_without_duplicates_column.append(\"\")\n",
    "\n",
    "            continue\n",
    "\n",
    " \n",
    "\n",
    "        sentences = sentence_endings.split(paragraph.strip())\n",
    "\n",
    "        filtered_sentences = []\n",
    "\n",
    "        duplicates_in_row = []\n",
    "\n",
    "        seen_cleaned = set()\n",
    "\n",
    " \n",
    "\n",
    "        for sentence in sentences:\n",
    "\n",
    "            cleaned = re.sub(r'\\W+', '', sentence.lower())\n",
    "\n",
    "            if cleaned in duplicate_cleaned:\n",
    "\n",
    "                if cleaned not in seen_cleaned:\n",
    "\n",
    "                    filtered_sentences.append(sentence.strip())  # keep first occurrence\n",
    "\n",
    "                    seen_cleaned.add(cleaned)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    duplicates_in_row.append(sentence.strip())  # subsequent duplicates\n",
    "\n",
    "            else:\n",
    "\n",
    "                filtered_sentences.append(sentence.strip())\n",
    "\n",
    "        # append to new line - \\n should not be present in the output to .csv        \n",
    "\n",
    "        duplicate_sentences_column.append('\\n'.join(duplicates_in_row))\n",
    "\n",
    "        texts_without_duplicates_column.append('\\n'.join(filtered_sentences))\n",
    "\n",
    " \n",
    "\n",
    "    # Add new columns to the DataFrame\n",
    "\n",
    "    df['duplicate_sentences'] = duplicate_sentences_column\n",
    "\n",
    "    df['text_without_duplicates'] = texts_without_duplicates_column\n",
    "\n",
    " \n",
    "\n",
    "    return df\n",
    "\n",
    " \n",
    "\n",
    "# Apply the function\n",
    "\n",
    "text_summary_df = extract_sentences_and_update_df(random_sample, 'transcript')\n",
    "\n",
    "text_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
